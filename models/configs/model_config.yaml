# Model Configuration for Crypto Forecasting

# LightGBM Hyperparameters
lightgbm:
  objective: 'regression'
  metric: 'rmse'
  boosting_type: 'gbdt'
  num_leaves: 31
  learning_rate: 0.05
  feature_fraction: 0.9
  bagging_fraction: 0.8
  bagging_freq: 5
  max_depth: -1
  min_data_in_leaf: 20
  n_estimators: 100
  verbose: -1

# LSTM Hyperparameters
lstm:
  sequence_length: 60
  n_features: 50  # Will be determined by feature engineering
  lstm_units_1: 128
  lstm_units_2: 64
  dense_units: 32
  dropout_rate: 0.2
  learning_rate: 0.001
  batch_size: 32
  epochs: 100
  early_stopping_patience: 10

# Ensemble Configuration
ensemble:
  lgb_weight: 0.6
  lstm_weight: 0.4
  use_meta_learner: true
  meta_model: 'ridge'  # ridge, lasso, or elasticnet

# Data Configuration
data:
  train_split: 0.70
  val_split: 0.15
  test_split: 0.15
  sequence_length: 60
  forecast_horizon: 7
  min_history_days: 90

# Feature Engineering
features:
  technical_indicators:
    - rsi
    - macd
    - bollinger_bands
    - atr
    - stochastic
    - ema_12
    - ema_26
    - sma_50
    - sma_200
  price_features:
    - returns
    - log_returns
    - volatility
    - volume_ratio
  time_features:
    - day_of_week
    - hour_of_day
    - is_weekend
  market_features:
    - btc_correlation
    - market_cap_dominance

# Training Configuration
training:
  cross_validation_splits: 5
  hyperparameter_tuning: true
  optimization_trials: 50
  save_best_only: true
  model_versioning: true

# Evaluation Metrics
metrics:
  - mape
  - rmse
  - mae
  - r2_score
  - sharpe_ratio
  - max_drawdown

