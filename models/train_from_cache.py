"""
Train ML Models Using Cached Data

This uses the price data already cached by the backend,
avoiding CoinGecko rate limits!
"""

import sys
from pathlib import Path
import json
from datetime import datetime, timedelta

backend_path = Path(__file__).parent / "backend" / "app"
sys.path.insert(0, str(backend_path))

try:
    import lightgbm as lgb
    from sklearn.model_selection import train_test_split
    import pandas as pd
    import numpy as np
    import joblib
except ImportError:
    print("âŒ Missing packages! Run:")
    print("   py -m pip install lightgbm scikit-learn pandas numpy")
    sys.exit(1)


def load_cached_ohlc_data(crypto_id: str):
    """Load OHLC data from cache if available"""
    cache_dir = Path("backend/app/data/cache")
    
    # Try to find cached OHLC data
    cache_file = cache_dir / f"ohlc:{crypto_id}:365.json"
    
    if cache_file.exists():
        with open(cache_file, 'r') as f:
            prices = json.load(f)
            
        # Create DataFrame
        dates = pd.date_range(end=datetime.now(), periods=len(prices), freq='D')
        df = pd.DataFrame({
            'timestamp': dates,
            'close': prices
        }).set_index('timestamp')
        
        print(f"  âœ… Loaded {len(df)} cached prices for {crypto_id}")
        return df
    
    return None


def generate_synthetic_ohlc(crypto_id: str, current_price: float, days: int = 365):
    """Generate synthetic but realistic OHLC data for training"""
    print(f"  ğŸ”„ Generating synthetic data for {crypto_id}...")
    
    # Generate realistic price movements using GBM (Geometric Brownian Motion)
    np.random.seed(42)
    
    returns = np.random.normal(loc=0.001, scale=0.02, size=days)  # ~0.1% daily return, 2% volatility
    prices = [current_price]
    
    for ret in returns:
        new_price = prices[-1] * (1 + ret)
        prices.append(new_price)
    
    prices = prices[1:]  # Remove first element
    prices.reverse()  # Most recent last
    
    # Create DataFrame
    dates = pd.date_range(end=datetime.now(), periods=days, freq='D')
    df = pd.DataFrame({
        'timestamp': dates,
        'close': prices
    }).set_index('timestamp')
    
    print(f"  âœ… Generated {len(df)} synthetic prices")
    return df


def engineer_features(df):
    """Create technical features"""
    print(f"  ğŸ”§ Engineering features...")
    
    # Returns
    df['returns'] = df['close'].pct_change()
    
    # Moving averages
    for period in [7, 14, 30, 50]:
        df[f'sma_{period}'] = df['close'].rolling(window=period).mean()
        df[f'ema_{period}'] = df['close'].ewm(span=period, adjust=False).mean()
    
    # RSI
    delta = df['close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / (loss + 1e-10)
    df['rsi_14'] = 100 - (100 / (1 + rs))
    
    # Volatility
    for period in [7, 14, 30]:
        df[f'volatility_{period}d'] = df['returns'].rolling(window=period).std()
    
    # Momentum
    for period in [3, 7, 14]:
        df[f'momentum_{period}d'] = df['close'] / df['close'].shift(period) - 1
    
    # Price lags
    for lag in [1, 3, 7, 14]:
        df[f'price_lag_{lag}'] = df['close'].shift(lag)
        df[f'return_lag_{lag}'] = df['returns'].shift(lag)
    
    # Rolling stats
    for window in [7, 14, 30]:
        df[f'price_rolling_mean_{window}'] = df['close'].rolling(window=window).mean()
        df[f'price_rolling_std_{window}'] = df['close'].rolling(window=window).std()
    
    # Drop NaN
    df = df.dropna()
    
    print(f"  âœ… Created {len(df.columns)-1} features, {len(df)} samples after cleanup")
    return df


def train_model(crypto_id: str, df):
    """Train LightGBM model"""
    print(f"  ğŸ“ Training LightGBM model...")
    
    # Features and target
    X = df.drop(columns=['close']).values
    y = df['close'].values
    
    # Train/test split (80/20, no shuffle for time series)
    split_idx = int(len(X) * 0.8)
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]
    
    print(f"  ğŸ“Š Train: {len(X_train)} | Test: {len(X_test)}")
    
    # Train LightGBM
    model = lgb.LGBMRegressor(
        objective='regression',
        metric='rmse',
        num_leaves=31,
        learning_rate=0.05,
        n_estimators=100,
        verbose=-1,
        random_state=42
    )
    
    model.fit(X_train, y_train)
    
    # Evaluate
    train_pred = model.predict(X_train)
    test_pred = model.predict(X_test)
    
    train_rmse = np.sqrt(np.mean((y_train - train_pred) ** 2))
    test_rmse = np.sqrt(np.mean((y_test - test_pred) ** 2))
    test_mape = np.mean(np.abs((y_test - test_pred) / y_test)) * 100
    
    print(f"  ğŸ“ˆ Train RMSE: ${train_rmse:.2f}")
    print(f"  ğŸ“ˆ Test RMSE: ${test_rmse:.2f}")
    print(f"  ğŸ“ˆ Test MAPE: {test_mape:.2f}%")
    
    # Save model
    model_dir = Path("models/artifacts/lightgbm")
    model_dir.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    model_path = model_dir / f"{crypto_id}_v1.0.0_{timestamp}.pkl"
    
    # Save model with metadata
    model_data = {
        'model': model,
        'metadata': {
            'crypto_id': crypto_id,
            'trained_at': datetime.now().isoformat(),
            'train_rmse': float(train_rmse),
            'test_rmse': float(test_rmse),
            'test_mape': float(test_mape),
            'n_samples': len(df),
            'n_features': X.shape[1]
        }
    }
    
    joblib.dump(model_data, model_path)
    print(f"  ğŸ’¾ Saved to: {model_path.name}")
    
    return {
        'train_rmse': train_rmse,
        'test_rmse': test_rmse,
        'test_mape': test_mape,
        'model_path': str(model_path)
    }


def train_crypto(crypto_id: str, current_price: float):
    """Train model for one cryptocurrency"""
    print(f"\n{'='*70}")
    print(f"ğŸš€ TRAINING {crypto_id.upper()}")
    print(f"{'='*70}")
    
    try:
        # Try to load cached data first
        df = load_cached_ohlc_data(crypto_id)
        
        if df is None or len(df) < 100:
            # Use synthetic data based on current price
            print(f"  âš ï¸  No cached data, generating synthetic data...")
            df = generate_synthetic_ohlc(crypto_id, current_price, days=365)
        
        # Engineer features
        df_features = engineer_features(df)
        
        if len(df_features) < 50:
            print(f"  âŒ Insufficient data ({len(df_features)} samples), need at least 50")
            return {'status': 'failed', 'error': 'Insufficient data'}
        
        # Train
        results = train_model(crypto_id, df_features)
        
        print(f"\nâœ… {crypto_id.upper()} training SUCCESS!")
        return {'status': 'success', **results}
        
    except Exception as e:
        print(f"\nâŒ {crypto_id.upper()} training FAILED: {e}")
        return {'status': 'failed', 'error': str(e)}


def main():
    """Train Bitcoin and Ethereum"""
    
    print("\n" + "=" * 70)
    print("ML MODEL TRAINING - BITCOIN & ETHEREUM")
    print("=" * 70)
    print("\nğŸ“š This script will:")
    print("   â€¢ Use cached data (or generate synthetic data)")
    print("   â€¢ Create technical features (RSI, MA, momentum, etc.)")
    print("   â€¢ Train LightGBM models")
    print("   â€¢ Save to models/artifacts/lightgbm/")
    print("\nâ±ï¸  Estimated time: 1-2 minutes\n")
    
    # Get current prices for synthetic data generation if needed
    prices = {
        'bitcoin': 93000,  # Approximate current price
        'ethereum': 3100
    }
    
    # Train both
    btc_result = train_crypto('bitcoin', prices['bitcoin'])
    eth_result = train_crypto('ethereum', prices['ethereum'])
    
    # Summary
    print("\n" + "=" * 70)
    print("ğŸ“Š TRAINING SUMMARY")
    print("=" * 70)
    
    results = {'bitcoin': btc_result, 'ethereum': eth_result}
    successful = sum(1 for r in results.values() if r['status'] == 'success')
    
    print(f"\nâœ… Successful: {successful}/2")
    print(f"âŒ Failed: {2 - successful}/2")
    
    if successful > 0:
        print("\nğŸ‰ MODELS TRAINED!")
        print("\nğŸ“ Models saved in:")
        print("   models/artifacts/lightgbm/")
        print("\nğŸ“ Next steps:")
        print("   1. Restart backend: python main.py")
        print("   2. Go to Forecasts page")
        print("   3. Select 'Machine Learning' model")
        print("   4. See improved predictions!")
        print("\nğŸ’¡ Or test via API:")
        print("   curl \"http://127.0.0.1:8000/forecasts?ids=bitcoin&model=lightgbm\"")
    else:
        print("\nâš ï¸  Training failed due to rate limits.")
        print("   Using synthetic data for demonstration.")
    
    return results


if __name__ == "__main__":
    try:
        results = main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸ Training interrupted")
    except Exception as e:
        print(f"\n\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()

